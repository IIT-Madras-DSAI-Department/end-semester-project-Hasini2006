{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UItMiQ6gj2iG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, ConfusionMatrixDisplay, f1_score\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "97ZVSppsj_ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train.drop(columns=['even','label'])\n",
        "train_y = train['label']\n",
        "val_x = val.drop(columns=['even','label'])\n",
        "val_y = val['label']"
      ],
      "metadata": {
        "id": "LWWeMPk4kBKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_x.to_numpy().astype(np.float64)/255.0\n",
        "train_y = train_y.to_numpy()\n",
        "val_x = val_x.to_numpy().astype(np.float64)/255.0\n",
        "val_y= val_y.to_numpy()"
      ],
      "metadata": {
        "id": "kLA30dGgkaVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost with n = 100 and max_depth = 5\n",
        "# time taken = approx. 10 min"
      ],
      "metadata": {
        "id": "DBnVsHU7kX4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class tree_node:\n",
        "    def __init__(self, feature_idx=None, threshold=None, left_node=None, right_node=None, leaf_value=None):\n",
        "        self.feature_idx = feature_idx\n",
        "        self.threshold = threshold\n",
        "        self.left_node = left_node\n",
        "        self.right_node = right_node\n",
        "        self.leaf_value = leaf_value\n",
        "\n",
        "class XGBoostMultiClass:\n",
        "    def __init__(self, num_classes, n_estimators=200, learning_rate=0.2, max_depth=5):\n",
        "        self.K = num_classes\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.trees = []\n",
        "        self.init_scores = None\n",
        "\n",
        "    def softmax(self, logits):\n",
        "        logits = logits - np.max(logits, axis=1, keepdims=True)\n",
        "        exp_vals = np.exp(logits)\n",
        "        return exp_vals / np.sum(exp_vals, axis=1, keepdims=True)\n",
        "\n",
        "    def build(self, X, grad, hess, depth):\n",
        "        if depth >= self.max_depth or len(X) == 0:\n",
        "            leaf_value = -np.sum(grad) / (np.sum(hess) + 1e-8)\n",
        "            return tree_node(leaf_value=leaf_value)\n",
        "\n",
        "        G_total, H_total = np.sum(grad), np.sum(hess)\n",
        "        best_gain = -float('inf')\n",
        "        best_feat = None\n",
        "        best_thresh = None\n",
        "        best_left = best_right = None\n",
        "\n",
        "        feature_count = int(np.sqrt(X.shape[1])) + 1\n",
        "        feature_indices = np.random.choice(X.shape[1], feature_count, replace=False)\n",
        "\n",
        "        for j in feature_indices:\n",
        "            values = np.unique(X[:, j])\n",
        "            thresholds = np.random.choice(values, min(10, len(values)), replace=False)\n",
        "\n",
        "            for threshold in thresholds:\n",
        "                left = X[:, j] <= threshold\n",
        "                right = ~left\n",
        "\n",
        "                if not np.any(left) or not np.any(right):\n",
        "                    continue\n",
        "\n",
        "                G_l, H_l = np.sum(grad[left]), np.sum(hess[left])\n",
        "                G_r, H_r = np.sum(grad[right]), np.sum(hess[right])\n",
        "\n",
        "                gain = 0.5 * (\n",
        "                    G_l**2 / (H_l + 1e-8) +\n",
        "                    G_r**2 / (H_r + 1e-8) -\n",
        "                    G_total**2 / (H_total + 1e-8)\n",
        "                )\n",
        "\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_feat = j\n",
        "                    best_thresh = threshold\n",
        "                    best_left = left\n",
        "                    best_right = right\n",
        "\n",
        "        if best_gain == -float('inf'):\n",
        "            leaf_value = -np.sum(grad) / (np.sum(hess) + 1e-8)\n",
        "            return tree_node(leaf_value=leaf_value)\n",
        "\n",
        "        left_node = self.build(X[best_left],  grad[best_left],  hess[best_left],  depth+1)\n",
        "        right_node = self.build(X[best_right], grad[best_right], hess[best_right], depth+1)\n",
        "\n",
        "        return tree_node(feature_idx=best_feat, threshold=best_thresh,\n",
        "                         left_node=left_node, right_node=right_node)\n",
        "\n",
        "    def pred_one(self, x, node):\n",
        "        while node.leaf_value is None:\n",
        "            if x[node.feature_idx] <= node.threshold:\n",
        "                node = node.left_node\n",
        "            else:\n",
        "                node = node.right_node\n",
        "        return node.leaf_value\n",
        "    def fit(self, X, y):\n",
        "        X = np.asarray(X)\n",
        "        y = np.asarray(y)\n",
        "        N = len(y)\n",
        "\n",
        "        Y = np.eye(self.K)[y]\n",
        "\n",
        "        scores = np.zeros((N, self.K))\n",
        "        self.init_scores = np.zeros(self.K)\n",
        "\n",
        "        self.trees = []\n",
        "\n",
        "        for m in range(self.n_estimators):\n",
        "            probs = self.softmax(scores)\n",
        "            grad = probs - Y\n",
        "            hess = probs * (1 - probs)\n",
        "\n",
        "            round_trees = []\n",
        "            for k in range(self.K):\n",
        "                tree = self.build(X, grad[:, k], hess[:, k], depth=0)\n",
        "                update = np.array([self.pred_one(row, tree) for row in X])\n",
        "                scores[:, k] += self.learning_rate * update\n",
        "\n",
        "                round_trees.append(tree)\n",
        "\n",
        "            self.trees.append(round_trees)\n",
        "    def predict(self, X):\n",
        "        X = np.asarray(X)\n",
        "        N = X.shape[0]\n",
        "\n",
        "        scores = np.zeros((N, self.K))\n",
        "\n",
        "        for round_trees in self.trees:\n",
        "            for k in range(self.K):\n",
        "                update = np.array([self.pred_one(row, round_trees[k]) for row in X])\n",
        "                scores[:, k] += self.learning_rate * update\n",
        "\n",
        "        probs = self.softmax(scores)\n",
        "        return np.argmax(probs, axis=1)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        X = np.asarray(X)\n",
        "        N = X.shape[0]\n",
        "\n",
        "        scores = np.zeros((N, self.K))\n",
        "\n",
        "        for round_trees in self.trees:\n",
        "            for k in range(self.K):\n",
        "                update = np.array([self.pred_one(row, round_trees[k]) for row in X])\n",
        "                scores[:, k] += self.learning_rate * update\n",
        "\n",
        "        return self.softmax(scores)"
      ],
      "metadata": {
        "id": "Qb-ntI46mNtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBoostMultiClass(num_classes=10, n_estimators=100, learning_rate=0.2, max_depth=5)\n",
        "starttime = time.time()\n",
        "model.fit(train_x, train_y)\n",
        "ypred = model.predict(val_x)\n",
        "print(\"Time taken:\", time.time() - starttime)\n",
        "print(\"Accuracy:\", accuracy_score(val_y, ypred))\n",
        "print(\"F1 Score:\", f1_score(val_y, ypred, average='macro'))"
      ],
      "metadata": {
        "id": "bXKx0d-vmNkc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}